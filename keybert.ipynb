{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3873a2d3",
   "metadata": {},
   "source": [
    "# KeyBERT Review\n",
    "\n",
    "### Derrick Luyen\n",
    "### ICS 691B Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2091f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keybert\n",
      "  Using cached keybert-0.7.0.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: sentence-transformers>=0.3.8 in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from keybert) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from keybert) (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from keybert) (1.23.5)\n",
      "Collecting rich>=10.4.0\n",
      "  Using cached rich-12.6.0-py3-none-any.whl (237 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from rich>=10.4.0->keybert) (2.11.2)\n",
      "Collecting commonmark<0.10.0,>=0.9.0\n",
      "  Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from scikit-learn>=0.22.2->keybert) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from scikit-learn>=0.22.2->keybert) (1.9.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from scikit-learn>=0.22.2->keybert) (1.2.0)\n",
      "Requirement already satisfied: nltk in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from sentence-transformers>=0.3.8->keybert) (3.7)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from sentence-transformers>=0.3.8->keybert) (4.24.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from sentence-transformers>=0.3.8->keybert) (0.11.0)\n",
      "Requirement already satisfied: torchvision in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from sentence-transformers>=0.3.8->keybert) (0.14.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from sentence-transformers>=0.3.8->keybert) (1.13.0)\n",
      "Requirement already satisfied: sentencepiece in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from sentence-transformers>=0.3.8->keybert) (0.1.97)\n",
      "Requirement already satisfied: tqdm in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from sentence-transformers>=0.3.8->keybert) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (4.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (6.0)\n",
      "Requirement already satisfied: requests in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.28.1)\n",
      "Requirement already satisfied: filelock in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.8.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (0.13.2)\n",
      "Requirement already satisfied: click in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from nltk->sentence-transformers>=0.3.8->keybert) (8.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from torchvision->sentence-transformers>=0.3.8->keybert) (9.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/derrickluyen/opt/anaconda3/envs/py310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.0.4)\n",
      "Building wheels for collected packages: keybert\n",
      "  Building wheel for keybert (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keybert: filename=keybert-0.7.0-py3-none-any.whl size=23776 sha256=2d78b06961a9d1e26f99d390a95a0e26a3448ba3636aa943cb8c056cc8488e4d\n",
      "  Stored in directory: /Users/derrickluyen/Library/Caches/pip/wheels/66/8d/e6/b0e2f8d883b0fd51819226f67ad9843e04913ce4a97241ff4b\n",
      "Successfully built keybert\n",
      "Installing collected packages: commonmark, rich, keybert\n",
      "Successfully installed commonmark-0.9.1 keybert-0.7.0 rich-12.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installation\n",
    "# %pip install keybert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18b2c5a",
   "metadata": {},
   "source": [
    "## What is KeyBERT?\n",
    "\n",
    "- KEYWORD EXTRACTION\n",
    "    - technique used to extract keywords\n",
    "- takes advantage of BERT embeddings to get the key words / phrases\n",
    "- extracts words that are most similar to content / meaning of document\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538ad97b",
   "metadata": {},
   "source": [
    "### Basic Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54bf8977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('supervised', 0.6676),\n",
       " ('labeled', 0.4896),\n",
       " ('learning', 0.4813),\n",
       " ('training', 0.4134),\n",
       " ('labels', 0.3947)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "doc = \"\"\"\n",
    "         Supervised learning is the machine learning task of learning a function that\n",
    "         maps an input to an output based on example input-output pairs. It infers a\n",
    "         function from labeled training data consisting of a set of training examples.\n",
    "         In supervised learning, each example is a pair consisting of an input object\n",
    "         (typically a vector) and a desired output value (also called the supervisory signal).\n",
    "         A supervised learning algorithm analyzes the training data and produces an inferred function,\n",
    "         which can be used for mapping new examples. An optimal scenario will allow for the\n",
    "         algorithm to correctly determine the class labels for unseen instances. This requires\n",
    "         the learning algorithm to generalize from the training data to unseen situations in a\n",
    "         'reasonable' way (see inductive bias).\n",
    "      \"\"\"\n",
    "\n",
    "kw_model = KeyBERT()\n",
    "keywords = kw_model.extract_keywords(doc)\n",
    "\n",
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f135c92",
   "metadata": {},
   "source": [
    "### Explanation of Values\n",
    "\n",
    "We see that with the most basic call to extract_keywords, we are given 5 words, each with a value associated with it. That value is the calculated cosine similarity of the word and represents how similar the word is to the rest of the document. With cosine similarity, we know the highest value is 1 while the lowest is -1 which explains why higher values lead to more similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ff2fee",
   "metadata": {},
   "source": [
    "## Underlying Workings of KeyBERT\n",
    "\n",
    "- Input: document(s) to extract keywords from\n",
    "- Step 1: extract document embeddings via BERT (BERT embeddings) to get document-level representation\n",
    "- Step 2: extract word embeddings from document embeddings to generate n-gram words / phrases\n",
    "    - n-gram meaning a contiguous sequence of n words in this case\n",
    "- Step 3: use cosine similarity on word embeddings to compare to full document to find out which words / phrases are the most similar to original document\n",
    "    - allows us to extract key words / phrases\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6bb11f",
   "metadata": {},
   "source": [
    "## KeyBERT Methods\n",
    "\n",
    "- KeyBERT API consists of two main methods:\n",
    "    - extract_embeddings(...)\n",
    "    - extract_keywords(...)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6338e7",
   "metadata": {},
   "source": [
    "## Extract Embeddings\n",
    "\n",
    "extract_embeddings(self, docs, candidates=None, keyphrase_ngram_range=(1, 1), stop_words='english', min_df=1, vectorizer=None)\n",
    "\n",
    "- used to extract document and word embeddings (Step 1 + Step 2 from earlier) \n",
    "    - document embeddings for input document\n",
    "    - word embeddings represent the embeddings of key words / phrases\n",
    "    \n",
    "- Returns:\n",
    "    - doc_embeddings: document embeddings for each input document\n",
    "    - word_embeddings: embeddings of POTENTIAL key words / phrases from the given input document(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee52fec",
   "metadata": {},
   "source": [
    "### Extract Embeddings Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5939ad9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-6.59579635e-02 -2.62582451e-02 -5.84359877e-02  2.30566636e-02\n",
      "   8.50326121e-02  4.17129025e-02  3.69997546e-02 -6.58201650e-02\n",
      "  -3.87015156e-02 -2.95363809e-03 -3.30499262e-02 -1.44510521e-02\n",
      "   5.30893803e-02  4.53584604e-02 -3.71540338e-02  3.82542983e-02\n",
      "   8.76147598e-02 -8.54388159e-03 -2.05052681e-02 -1.00440502e-01\n",
      "   3.98336798e-02  2.59869397e-02 -4.42725830e-02  5.32478541e-02\n",
      "  -4.35705557e-02  6.08860105e-02  3.51422019e-02  1.28424191e-03\n",
      "  -8.47642217e-03 -3.32369134e-02  2.45928876e-02 -4.37021479e-02\n",
      "   1.95506550e-02 -2.32752077e-02 -7.13654310e-02  2.95184217e-02\n",
      "  -5.31128272e-02  8.29254314e-02  1.79729536e-02 -4.40264381e-02\n",
      "   6.71629189e-03  3.34282182e-02 -2.02634130e-02  7.17922486e-03\n",
      "   6.06902204e-02  7.60842115e-02  2.87512783e-02 -5.89286201e-02\n",
      "  -9.60301980e-02  4.31644022e-02 -8.03859383e-02 -2.43355948e-02\n",
      "  -5.58135509e-02  3.92430387e-02 -3.63611020e-02 -1.13825584e-02\n",
      "   4.60491255e-02 -5.44759743e-02 -3.21346484e-02  6.92857802e-02\n",
      "   4.05919328e-02 -9.25480053e-02 -1.20178405e-02  3.38483648e-03\n",
      "   2.47528721e-02 -5.10513857e-02 -4.71547060e-03 -2.81510092e-02\n",
      "  -3.29866931e-02 -6.24616668e-02  3.51051576e-02  7.11539313e-02\n",
      "  -1.22090895e-02  2.20728926e-02  6.58348054e-02 -1.85684394e-02\n",
      "   1.58891585e-02  2.05849968e-02  4.97750975e-02  5.14318992e-04\n",
      "  -1.07067814e-02  3.21278796e-02  4.89481958e-03  2.29609404e-02\n",
      "   1.33996457e-01 -2.03497428e-02 -1.01014338e-02 -3.23385256e-03\n",
      "   1.86223164e-03  8.68496448e-02 -7.31765404e-02 -6.37987331e-02\n",
      "  -1.04203500e-01 -2.45212279e-02 -8.75536054e-02 -4.32481542e-02\n",
      "  -8.14334676e-03 -3.20247076e-02  5.27848750e-02  8.10106769e-02\n",
      "  -8.81583169e-02  7.95038715e-02  1.89339509e-03 -3.78542244e-02\n",
      "  -2.51657311e-02  2.51893494e-02 -6.47991989e-03 -6.85287789e-02\n",
      "   1.20860375e-01 -9.23453420e-02 -2.68241484e-02 -1.74136050e-02\n",
      "  -9.78136808e-02  1.23559346e-03 -4.23848076e-04 -2.14971099e-02\n",
      "   3.10618859e-02  2.18983414e-03 -6.32215068e-02  6.35793135e-02\n",
      "  -4.79216762e-02 -2.89728325e-02  8.18772316e-02  9.14352387e-02\n",
      "  -5.43998033e-02 -2.87247244e-02 -8.59841555e-02  2.65788709e-34\n",
      "   3.02150683e-03 -9.91961285e-02 -9.10557155e-03 -3.61363031e-02\n",
      "   4.30554710e-02 -6.35391548e-02 -6.48405850e-02  5.46675082e-03\n",
      "   5.98950796e-02  6.43365234e-02  4.47356440e-02 -2.78135948e-02\n",
      "   6.63355216e-02  7.47369155e-02 -3.83799151e-03 -5.79445064e-03\n",
      "  -2.45200507e-02  7.99367875e-02 -3.06397881e-02 -8.20871294e-02\n",
      "  -3.09578702e-02  2.87072882e-02  1.71526372e-02 -5.26083596e-02\n",
      "   2.54840553e-02  4.20914739e-02 -1.62964850e-03  2.18193773e-02\n",
      "   5.64957000e-02  1.54433853e-03  1.23385331e-02 -4.35653608e-03\n",
      "  -2.95356698e-02  6.18090155e-04  3.92428003e-02  1.26664042e-02\n",
      "   6.51749406e-06  5.91429489e-05  4.37822454e-02  1.38785848e-02\n",
      "   5.59151219e-03 -3.53771150e-02  6.68058023e-02 -4.41111065e-02\n",
      "  -4.39193361e-02  9.06770583e-03 -3.73114198e-02 -6.50375113e-02\n",
      "  -4.61265892e-02 -2.42730621e-02 -5.37549891e-03 -7.38403052e-02\n",
      "   2.45618075e-02 -1.90240983e-02 -3.86961438e-02  1.17142089e-01\n",
      "   7.77896307e-03  2.05936152e-02 -2.40098126e-02 -1.19238021e-02\n",
      "   4.60626483e-02  1.21449847e-02 -1.38792461e-02  5.18240072e-02\n",
      "  -1.12661282e-02  1.82789210e-02  6.30898103e-02 -1.00815482e-02\n",
      "   1.29445106e-01  4.77541192e-03 -9.07414127e-03  5.93460016e-02\n",
      "  -2.56465487e-02 -1.66222882e-02  8.30108970e-02  1.94760282e-02\n",
      "  -3.45548126e-03 -6.24274202e-02 -1.51121514e-02  4.26034853e-02\n",
      "  -4.23447555e-03 -1.83500703e-02 -1.10866409e-02 -8.42537433e-02\n",
      "  -4.52811420e-02 -1.41582068e-03 -4.41226438e-02 -4.01220657e-02\n",
      "   1.09817917e-02  3.01299207e-02 -1.15602344e-01  3.61451767e-02\n",
      "  -6.48752302e-02  4.83352877e-02  6.03185222e-02 -2.33045906e-33\n",
      "  -3.79601195e-02  9.21446756e-02 -2.57957801e-02  3.20161059e-02\n",
      "  -1.81577504e-02  1.65850371e-02 -5.24726324e-02  6.81604743e-02\n",
      "  -4.56911623e-02  5.15552722e-02 -8.71625450e-03 -1.92747544e-02\n",
      "   2.26287474e-03  6.50706664e-02 -6.57982901e-02  7.29076192e-02\n",
      "  -5.71689494e-02 -3.55880670e-02 -3.40939239e-02  3.55007835e-02\n",
      "  -3.60611780e-03  1.18641928e-01 -1.28038786e-03  2.74649728e-02\n",
      "   1.86599270e-02  2.51976177e-02  1.13816224e-02  3.80895026e-02\n",
      "   3.32392640e-02  5.41304983e-02 -4.06520702e-02 -6.30437434e-02\n",
      "  -1.69787575e-02 -5.30074202e-02 -5.86850494e-02  4.01312895e-02\n",
      "   9.51897874e-02 -3.12486757e-02 -4.83359396e-02  7.67844841e-02\n",
      "  -1.81771033e-02  9.10663083e-02 -7.93389753e-02 -7.71361915e-03\n",
      "  -2.28784382e-02 -9.68439355e-02 -2.28941999e-02  4.52446342e-02\n",
      "   1.70851760e-02 -1.18820295e-02 -4.06755023e-02  5.60234487e-02\n",
      "  -8.94420519e-02 -5.22594303e-02 -1.06289029e-01 -5.06013483e-02\n",
      "  -1.06266448e-02  2.33585425e-02  4.55362648e-02  3.91934142e-02\n",
      "  -5.00924215e-02 -3.30402777e-02 -1.02820592e-02  5.88442534e-02\n",
      "  -1.86757476e-03  1.14445761e-02 -1.87118873e-02  4.39912453e-02\n",
      "   6.71923533e-02 -4.13008686e-03  6.07469194e-02  6.04384169e-02\n",
      "  -3.79638560e-02  3.21814679e-02 -2.10239403e-02 -4.88420725e-02\n",
      "  -9.30591114e-03 -8.37088823e-02 -4.84574251e-02 -1.29831154e-02\n",
      "   7.16884956e-02 -1.16679654e-01  2.72960998e-02  5.12492098e-02\n",
      "   4.02702168e-02  2.28133406e-02  6.67531863e-02 -1.91695858e-02\n",
      "   2.11915839e-02 -7.75681213e-02 -2.40363646e-03  7.52693638e-02\n",
      "  -7.30238110e-02  5.99632636e-02 -1.18858740e-01 -5.01356858e-08\n",
      "  -9.47455540e-02 -6.85152709e-02  3.27610783e-02 -9.00472701e-03\n",
      "   2.64590755e-02 -2.59177424e-02 -1.59127060e-02  1.98000018e-02\n",
      "  -1.82978883e-02 -8.48122612e-02  3.55534963e-02 -5.09894639e-03\n",
      "  -3.88690680e-02  2.39237510e-02  6.34049028e-02  1.60551071e-02\n",
      "   5.37269972e-02  5.94139807e-02  2.93655731e-02  6.10098690e-02\n",
      "   2.49586347e-02 -1.53672369e-02 -1.47974014e-03  5.51229231e-02\n",
      "   7.50003457e-02 -1.14695914e-01  3.15347873e-03  8.17444101e-02\n",
      "  -1.66899953e-02  4.12958153e-02 -4.46285680e-02  8.55951458e-02\n",
      "   7.14321434e-02 -1.13334246e-02  8.37561712e-02  1.44941494e-01\n",
      "   2.61440827e-03 -1.03512913e-01 -5.56268357e-02 -6.91423891e-03\n",
      "  -6.75634965e-02  1.15450367e-01 -6.29073083e-02 -3.91279943e-02\n",
      "  -1.70068396e-03  3.46208252e-02  8.06523934e-02 -7.27853030e-02\n",
      "  -5.62258288e-02 -3.53810191e-02  4.54546534e-04  1.92376617e-02\n",
      "   3.29284519e-02  1.22157428e-02  4.53196578e-02  7.00420979e-03\n",
      "   1.93624534e-02 -9.88141447e-02 -1.29424706e-02  7.20112696e-02\n",
      "   2.81029823e-03  8.76084194e-02  7.91995600e-02 -3.18247899e-02]]\n"
     ]
    }
   ],
   "source": [
    "doc_embeddings, word_embeddings = kw_model.extract_embeddings(doc)\n",
    "print(doc_embeddings) # represents the entire document embedding for the input doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35e1e1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 384)\n"
     ]
    }
   ],
   "source": [
    "print(word_embeddings.shape) # tells us that there are 50 potential keywords from the document above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f2c595",
   "metadata": {},
   "source": [
    "Doc_embeddings and word_embeddings can then be passed to extract_keywords as parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "820bd00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('supervised', 0.6676), ('labeled', 0.4896), ('learning', 0.4813), ('training', 0.4134), ('labels', 0.3947)]\n"
     ]
    }
   ],
   "source": [
    "keywords = kw_model.extract_keywords(doc, doc_embeddings=doc_embeddings, word_embeddings=word_embeddings)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7eaa00",
   "metadata": {},
   "source": [
    "# ADD SOME MORE HERE ABOUT PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c38ead2",
   "metadata": {},
   "source": [
    "As we can see, the keywords here are the same as above, so we can either get the document + word embeddings to pass to the extract keywords method, or we can simply use extract keywords, which will take care of the embeddings by itself on its way to extracting the keywords."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d73c2f",
   "metadata": {},
   "source": [
    "## Extract Keywords\n",
    "\n",
    "extract_keywords(self, docs, candidates=None, keyphrase_ngram_range=(1, 1), stop_words='english', top_n=5, min_df=1, use_maxsum=False, use_mmr=False, diversity=0.5, nr_candidates=20, vectorizer=None, highlight=False, seed_keywords=None, doc_embeddings=None, word_embeddings=None)\n",
    "\n",
    "- method used to extract key words or key phrases\n",
    "    - can pass in multiple documents at once\n",
    "- uses cosine similarity to find words / phrases with closest distance to the entire document(s)\n",
    "\n",
    "- returns: top n keywords with the closest cosine similarity to input document, n is default set to 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74e1203",
   "metadata": {},
   "source": [
    "Basic example is shown above, so here are some examples of the parameters we can use:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a1a5d2",
   "metadata": {},
   "source": [
    "# ADD SOME MORE HERE ABOUT PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d4f87a",
   "metadata": {},
   "source": [
    "## Using KeyBERT to extract keywords from a real dataset\n",
    "\n",
    "- Dataset URL: https://www.kaggle.com/datasets/anandhuh/covid-abstracts?resource=download\n",
    "    - contains 10,000 research papers\n",
    "        - each entry contains a title, abstract, and the url of the paper\n",
    "- using KeyBERT to extract keywords from a COVID-19 Research Paper dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff42d60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "csvFile = pandas.read_csv('./data/covid_abstracts.csv')\n",
    "\n",
    "print(len(csvFile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a8c8383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "abstracts = []\n",
    "for abstract in csvFile['abstract']:\n",
    "    abstracts.append(abstract)\n",
    "    \n",
    "print(len(abstracts)) # contains all abstracts of the 10,000 research papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cdc617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
